Concept,Mengdi,Nidhi,Mingyan,Mengdi (after),Nidhi (after),Mingyan (after),Notes
['multinomial naive bayes'],1,1,1,1,1,1,
['multinomial nb model'],1,1,1,1,1,1,
['probabilistic learning method'],1,1,1,1,1,1,
"['term', 'terms']",1,1,1,1,1,1,
"['document', 'documents']",1,1,1,1,1,1,
['class'],1,1,1,1,1,1,
['prior probability'],1,1,1,1,1,1,
['tokens'],1,1,1,1,1,1,
['vocabulary'],1,1,1,1,1,1,
['classification'],1,1,1,1,1,1,
['stop words'],1,1,1,1,1,1,
['text classification'],1,1,1,1,1,1,
['nb classification'],1,1,1,1,1,1,
['maximum a posteriori class'],1,1,0,1,1,1,
['training set'],1,1,1,1,1,1,
['maximum likelihood estimate'],1,1,1,1,1,1,
['training data'],1,1,1,1,1,1,
"['conditional probability', 'conditional probabilities']",1,1,1,1,1,1,
['conditional probability'],1,1,1,1,1,1,
['conditional probabilities'],1,1,1,1,1,1,
['positional independence assumption'],1,1,1,1,1,1,
['mle estimate'],1,1,1,1,1,1,
['sparseness'],1,1,1,1,1,1,
['laplace smoothing'],1,1,1,1,1,1,
['add-one smoothing'],1,1,1,1,1,1,
['uniform prior'],1,1,1,1,1,1,
['nb'],1,1,1,1,1,1,
['time complexity'],1,1,1,1,1,1,
['training collection'],1,1,1,1,1,1,
"['test document', 'test documents']",1,1,1,1,1,1,
['text classification method'],1,1,1,1,1,1,
['multinomial unigram language model'],1,1,1,1,1,1,
['language modeling'],1,1,1,1,1,1,
['naive bayes text classification'],1,1,1,1,1,1,
['maximum a posteriori'],1,1,1,1,1,1,
['term weights'],1,1,1,1,1,1,
['supervised learning method'],1,1,1,1,1,1,
['multinomial naive bayes model'],1,1,1,1,1,1,
['training documents'],1,1,1,1,1,1,
['nb classifier'],1,1,1,1,1,1,
['query'],1,1,1,1,1,1,
['add-1/2 smoothing'],1,0,1,1,1,1,